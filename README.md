# ğŸš€ Observabilidade no Databricks â€“ Projeto Completo

Monitore e aumente a **confiabilidade, performance e custo** dos jobs e clusters Databricks com **Prometheus + Grafana + Alertmanager**.  
Este projeto demonstra como aplicar **observabilidade e prÃ¡ticas SRE** em um ambiente **Data Lake / Big Data** baseado em **Databricks + AWS**.

---

## ğŸ§  Conceito â€“ O que Ã© o Databricks?

O **Databricks** Ã© uma plataforma unificada de anÃ¡lise de dados e IA construÃ­da sobre o **Apache Spark**, que permite:
- Criar pipelines de dados escalÃ¡veis (ETL/ELT);
- Treinar e servir modelos de machine learning;
- Analisar dados em larga escala em **Data Lakes (Lakehouse Architecture)**;
- Integrar com AWS, Azure e GCP.

Ele combina **Data Engineering + Data Science + Analytics** em um Ãºnico ambiente colaborativo, com notebooks, jobs e clusters gerenciados.

---

## ğŸ” Observabilidade no Databricks

A observabilidade permite **entender o comportamento interno do sistema** a partir de logs, mÃ©tricas e traces.  
No contexto Databricks, isso significa:

| Tipo | Exemplos | Ferramentas |
|------|-----------|-------------|
| ğŸ“ˆ MÃ©tricas | Jobs concluÃ­dos, duraÃ§Ã£o mÃ©dia, custo do cluster | Prometheus + Exporters |
| ğŸ“œ Logs | ExecuÃ§Ãµes, erros Spark, logs de driver/executor | CloudWatch Logs, Log Analytics |
| ğŸ” Traces | LatÃªncia de pipelines, dependÃªncias ETL | OpenTelemetry, Datadog APM |

### ğŸ”— IntegraÃ§Ã£o de Observabilidade

1. **Databricks Exporter (custom Python)** coleta mÃ©tricas via API REST (jobs, clusters, runs).  
2. **Prometheus** armazena as mÃ©tricas.  
3. **Grafana** visualiza os SLIs/SLOs.  
4. **Alertmanager** dispara alertas proativos (ex: job falhando, latÃªncia alta).  

---

## ğŸ§± Estrutura do Projeto

```
databricks-observability/
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ grafana-databricks-dashboard.json
â”œâ”€â”€ exporters/
â”‚   â””â”€â”€ databricks-metrics-exporter.py
â”œâ”€â”€ slo/
â”‚   â””â”€â”€ databricks-slo.yaml
â”œâ”€â”€ alerts/
â”‚   â””â”€â”€ alertmanager-rules.yaml
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture_overview.md
â””â”€â”€ README.md
```

---

## ğŸ§© VisÃ£o Geral do Dashboard

**Nome:** ğŸ§© Databricks Reliability â€“ Jobs & Clusters  
**Objetivo:** Monitorar confiabilidade, performance e custo dos jobs e clusters Databricks.

### ğŸ“ PainÃ©is principais

- VisÃ£o geral de confiabilidade (SLI/SLO geral)  
- Databricks Jobs â€“ sucesso e duraÃ§Ã£o  
- Clusters â€“ performance, custo e uso de recursos  
- Alertas e falhas recentes  

---

## ğŸ“Š Estrutura do Dashboard (visÃ£o hierÃ¡rquica)

```
ğŸ“Š Databricks Reliability Dashboard
â”œâ”€â”€ 1ï¸âƒ£ Overview
â”‚   â”œâ”€â”€ SLI: % de jobs concluÃ­dos
â”‚   â”œâ”€â”€ SLI: Tempo mÃ©dio de execuÃ§Ã£o (P95)
â”‚   â””â”€â”€ SLO: 99% jobs completando < 15min
â”œâ”€â”€ 2ï¸âƒ£ Databricks Jobs
â”‚   â”œâ”€â”€ Painel: Taxa de sucesso dos jobs
â”‚   â”œâ”€â”€ Painel: DuraÃ§Ã£o mÃ©dia dos jobs
â”‚   â”œâ”€â”€ Painel: Falhas por tipo
â”‚   â””â”€â”€ Painel: Tempo de fila/execuÃ§Ã£o
â”œâ”€â”€ 3ï¸âƒ£ Clusters
â”‚   â”œâ”€â”€ Painel: Uso de CPU e memÃ³ria
â”‚   â”œâ”€â”€ Painel: Tempo de inicializaÃ§Ã£o
â”‚   â”œâ”€â”€ Painel: Custo estimado
â”‚   â””â”€â”€ Painel: Capacidade ociosa
â””â”€â”€ 4ï¸âƒ£ Alertas e Logs
    â”œâ”€â”€ Painel: Alertas crÃ­ticos (Alertmanager)
    â””â”€â”€ Painel: Ãšltimos logs de falha (CloudWatch)
```

---

## ğŸ§® Exemplo de MÃ©tricas e Consultas (PromQL)

### ğŸ”¹ Jobs Databricks

| MÃ©trica | DescriÃ§Ã£o | Fonte | SLI | SLO |
|----------|------------|--------|------|------|
| `databricks_job_run_success_total` | Total de execuÃ§Ãµes bem-sucedidas | Exporter | % sucesso = sucesso / total | â‰¥ 99% |
| `databricks_job_run_duration_seconds` | DuraÃ§Ã£o mÃ©dia dos jobs | Exporter | P95 < 900s | â‰¤ 15 min |
| `databricks_job_run_failed_total` | Total de falhas | Exporter | â€” | â€” |

**Consultas PromQL simuladas:**

```promql
# SLI 1: Taxa de sucesso dos jobs (7d)
(sum(increase(databricks_job_run_success_total[7d])) 
 / sum(increase(databricks_job_run_started_total[7d]))) * 100

# SLI 2: DuraÃ§Ã£o mÃ©dia (15min window)
avg_over_time(databricks_job_run_duration_seconds[15m])
```

---

### ğŸ”¹ Clusters Databricks

| MÃ©trica | DescriÃ§Ã£o | Fonte | SLI | SLO |
|----------|------------|--------|------|------|
| `databricks_cluster_cpu_utilization` | Uso mÃ©dio de CPU por cluster | Exporter | < 80% | â€” |
| `databricks_cluster_memory_usage` | Uso mÃ©dio de memÃ³ria | Exporter | < 85% | â€” |
| `databricks_cluster_cost_estimated` | Custo estimado (USD/h) | Exporter | â€” | â€” |

```promql
# LatÃªncia mÃ©dia (P95)
histogram_quantile(0.95, sum(rate(databricks_job_run_duration_seconds_bucket[5m])) by (le))
```

---

## ğŸ§® Exemplo de DefiniÃ§Ã£o de SLO (YAML)

```yaml
service: "databricks-pipelines"
indicators:
  - name: "job_success_rate"
    metric_query: |
      (sum(increase(databricks_job_run_success_total[30d])) 
       / sum(increase(databricks_job_run_started_total[30d]))) * 100
    target: 99.0
    alert:
      warning: "< 99"
      critical: "< 98"
  - name: "job_duration_p95"
    metric_query: |
      histogram_quantile(0.95, sum(rate(databricks_job_run_duration_seconds_bucket[5m])) by (le))
    target: 900
    alert:
      warning: "> 900"
      critical: "> 1200"
```

---

## âš™ï¸ Passo a Passo â€“ ExecuÃ§Ã£o Local

### 1ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone https://github.com/seuusuario/databricks-observability.git
cd databricks-observability
```

### 2ï¸âƒ£ Criar o ambiente virtual

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configurar variÃ¡veis de ambiente

```bash
export DATABRICKS_HOST="https://<seu-workspace>.cloud.databricks.com"
export DATABRICKS_TOKEN="<seu-token-api>"
```

### 4ï¸âƒ£ Executar o Exporter

```bash
python exporters/databricks-metrics-exporter.py
```

O serviÃ§o ficarÃ¡ disponÃ­vel em `http://localhost:9101/metrics` para coleta pelo Prometheus.

---

### 5ï¸âƒ£ Configurar Prometheus

Adicione ao seu `prometheus.yml`:

```yaml
scrape_configs:
  - job_name: "databricks"
    static_configs:
      - targets: ["localhost:9101"]
```

### 6ï¸âƒ£ Importar o Dashboard no Grafana

- Acesse **Grafana â†’ Dashboards â†’ Import**
- Cole o conteÃºdo de `dashboards/grafana-databricks-dashboard.json`
- Conecte Ã  fonte de dados Prometheus (`http://localhost:9090`)

---

### 7ï¸âƒ£ Configurar Alertmanager (opcional)

Adicione em `alertmanager.yml`:

```yaml
route:
  receiver: 'slack'
receivers:
  - name: 'slack'
    slack_configs:
      - send_resolved: true
        channel: '#alerts'
        username: 'AlertBot'
        text: '{{ .CommonAnnotations.summary }}'
```

---

## ğŸ“ˆ Exemplo Visual (conceitual)

```
ğŸŸ¢ Job Success Rate (SLI)
â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡  99.3%

ğŸ• Job Duration (P95)
â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡  870s

ğŸ”¥ Cluster CPU Utilization
â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡  72%

ğŸ’¸ Cost Trend (USD/dia)
ğŸ’¹ line chart showing EC2 + Databricks compute cost

âš ï¸ Recent Incidents
Job â€œetl_customer_dataâ€ failed @ 2025-10-31T08:45
```

---

## ğŸš€ Nota Pessoal

> â€œEu implementaria observabilidade completa no Databricks com Prometheus e Grafana, monitorando SLIs e SLOs como taxa de sucesso e latÃªncia P95 dos jobs.  
> As mÃ©tricas seriam expostas via exporter customizado, correlacionadas com custo e uso de clusters, para detectar gargalos antes de afetar o negÃ³cio.â€

---

## ğŸ“š CrÃ©ditos e InspiraÃ§Ã£o

- [Databricks REST API](https://docs.databricks.com/api)
- [Prometheus Exporters](https://prometheus.io/docs/instrumenting/exporters/)
- [Grafana Dashboards](https://grafana.com/grafana/dashboards)
- [Alertmanager Rules](https://prometheus.io/docs/alerting/latest/alertmanager/)

---

## ğŸ§© LicenÃ§a
MIT License Â© 2025 [Pierre Santos](https://github.com/pmagaiwer/)
ğŸ“ Projeto pessoal para fins de estudo e demonstraÃ§Ã£o de prÃ¡ticas SRE em Data Lake/Big Data.
